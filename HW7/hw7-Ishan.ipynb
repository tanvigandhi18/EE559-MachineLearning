{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Name: Ishaan Thanekar\n",
    "* USCID: 876551769\n",
    "* Homework 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('HW7_Pr1_S24_training_data.csv')\n",
    "df_t = pd.read_csv('HW7_Pr1_S24_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028453</td>\n",
       "      <td>0.867236</td>\n",
       "      <td>-0.156244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.526357</td>\n",
       "      <td>0.754168</td>\n",
       "      <td>-1.452209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.741746</td>\n",
       "      <td>-0.112823</td>\n",
       "      <td>-0.803381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.711261</td>\n",
       "      <td>-0.415092</td>\n",
       "      <td>-2.281739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009440</td>\n",
       "      <td>0.841013</td>\n",
       "      <td>-0.007648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2         y\n",
       "0  0.028453  0.867236 -0.156244\n",
       "1 -0.526357  0.754168 -1.452209\n",
       "2  0.741746 -0.112823 -0.803381\n",
       "3  0.711261 -0.415092 -2.281739\n",
       "4 -0.009440  0.841013 -0.007648"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    0\n",
       "x2    0\n",
       "y     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(dataframe):\n",
    "    dataframe = dataframe.to_numpy()\n",
    "    features = dataframe[:,:-1]\n",
    "    labels = dataframe[:,-1]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model function:\n",
    "\n",
    "def baseline(features, labels, folds):\n",
    "    kfolds = KFold(n_splits=folds, shuffle = True, random_state = 42)\n",
    "    errors = []\n",
    "    for x, y in kfolds.split(features):\n",
    "        y_train, y_val = labels[x], labels[y]\n",
    "        train_X, val_X = features[x], features[y]\n",
    "        \n",
    "        # defining the model: Linear Regression:\n",
    "        model = LinearRegression()\n",
    "        model.fit(train_X, y_train)\n",
    "        preds = model.predict(val_X)\n",
    "        # implementing RMSE according to the formula given to us:\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        errors.append(rmse)\n",
    "        print(errors)\n",
    "    # given is the average RMSE on the validation sets for baseline\n",
    "    return np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4119907651553927]\n",
      "[2.4119907651553927, 2.466179520216617]\n",
      "[2.4119907651553927, 2.466179520216617, 2.407442766333652]\n",
      "[2.4119907651553927, 2.466179520216617, 2.407442766333652, 2.5226750780283713]\n",
      "[2.4119907651553927, 2.466179520216617, 2.407442766333652, 2.5226750780283713, 2.3091403874066456]\n",
      "Average RMSE on the validation sets is:  2.4234857034281356\n"
     ]
    }
   ],
   "source": [
    "features, labels = data(df)\n",
    "answerB = baseline(features, labels, folds=5)\n",
    "print(f\"Average RMSE on the validation sets is:  {answerB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Implementing the RBF Network as mentioned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's implement the rbf kernel from scratch as mentioned in equatiuon instead of importing because why not!\n",
    "# Network:\n",
    "\n",
    "# Here I first tested with my own rbf function but its optimal value varied when I used rbf_kernel\n",
    "# so i used rbf_kernel a fucntion provided by sklearn which is optimized properly....\n",
    "\n",
    "\"\"\"def rbf(x, u, gamma):\n",
    "    d = euclidean_distances(x, u)\n",
    "    # calculating the similarity score through rbf:\n",
    "    return np.exp(-gamma * np.square(d))\"\"\"\n",
    "\n",
    "\n",
    "def linear_model(features, labels):\n",
    "    \"\"\"I created this function as it was generating errors when I use Linear \n",
    "    Regression model directly inside my loop below, reference was taken after\n",
    "    contacting the TA's and discussing with a few peers\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(features, labels)\n",
    "    return model\n",
    "\n",
    "# Now we create a model selection function for gammas using gamma d's\n",
    "\"\"\"Note: So here and earlier the optimization of using kfolds.split was taken through a \n",
    " Stack Overflow Post fetauring optimization in model_selection for best fit\"\"\"\n",
    " \n",
    "def model_select_one(features, labels, gammas, folds = 5):\n",
    "    errors = []\n",
    "    valid_errors = []\n",
    "    std_errors = []\n",
    "    std_val_errors = []\n",
    "    kfolds = KFold(n_splits=folds)\n",
    "    for g in gammas:\n",
    "        train_errors = []\n",
    "        val_errors = []\n",
    "        for x, y in kfolds.split(features):\n",
    "            y_train, y_val = labels[x], labels[y]\n",
    "            train_X, val_X = features[x], features[y]\n",
    "            # defining feature space of phi-m as mentioned:\n",
    "            # here i define phi-m as m\n",
    "            m_tr = rbf_kernel(train_X, gamma=g)\n",
    "            model = linear_model(m_tr, y_train)\n",
    "            train_preds = model.predict(m_tr)\n",
    "            \n",
    "            # um's are the training of X i.e train_X\n",
    "            m_val = rbf_kernel(val_X, train_X, g)\n",
    "            val_preds = model.predict(m_val)\n",
    "            # according to the formula\n",
    "            rmse_tr = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "            rmse_val = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "            train_errors.append(rmse_tr)\n",
    "            val_errors.append(rmse_val)\n",
    "        \n",
    "        errors.append(np.mean(train_errors)) \n",
    "        valid_errors.append(np.mean(val_errors))\n",
    "        std_errors.append(np.std(train_errors))\n",
    "        std_val_errors.append(np.std(val_errors))\n",
    "         \n",
    "    return errors, valid_errors, std_errors, std_val_errors       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.88 MiB for an array with shape (800, 800) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m gamma_ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m      9\u001b[0m gammas \u001b[38;5;241m=\u001b[39m [gamma_d \u001b[38;5;241m*\u001b[39m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m gamma_]\n\u001b[1;32m---> 11\u001b[0m tot_errors, valid_tot_error, std_train, std_val \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_select_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m gamma_star \u001b[38;5;241m=\u001b[39m gammas[np\u001b[38;5;241m.\u001b[39margmin(valid_tot_error)]\n\u001b[0;32m     14\u001b[0m rmse_star \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(valid_tot_error)\n",
      "Cell \u001b[1;32mIn[9], line 40\u001b[0m, in \u001b[0;36mmodel_select_one\u001b[1;34m(features, labels, gammas, folds)\u001b[0m\n\u001b[0;32m     37\u001b[0m train_X, val_X \u001b[38;5;241m=\u001b[39m features[x], features[y]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# defining feature space of phi-m as mentioned:\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# here i define phi-m as m\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m m_tr \u001b[38;5;241m=\u001b[39m \u001b[43mrbf_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m linear_model(m_tr, y_train)\n\u001b[0;32m     42\u001b[0m train_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(m_tr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1540\u001b[0m, in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gamma \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1538\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m-> 1540\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1541\u001b[0m K \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mgamma\n\u001b[0;32m   1542\u001b[0m np\u001b[38;5;241m.\u001b[39mexp(K, K)  \u001b[38;5;66;03m# exponentiate K in-place\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:347\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    342\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    343\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m         )\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:382\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[0;32m    379\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[0;32m    384\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    196\u001b[0m ):\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.88 MiB for an array with shape (800, 800) and data type float64"
     ]
    }
   ],
   "source": [
    "# defining Gamma d as we got in the a) part: M/32 and resubstituting with delta_x:\n",
    "\n",
    "# M = 800, as 1000 * 4/5: Kfold = 5\n",
    "gamma_d = 800/32\n",
    "\n",
    "#gamma_d = 1 / 8 * np.mean((np.max(features, axis = 0) - np.min(features, axis = 0) / features.shape[0]**(1/features.shape[1]))**2)\n",
    "\n",
    "gamma_ = [0.01, 0.1, 1, 10, 100]\n",
    "gammas = [gamma_d * i for i in gamma_]\n",
    "\n",
    "tot_errors, valid_tot_error, std_train, std_val = model_select_one(features, labels, gammas)\n",
    "\n",
    "gamma_star = gammas[np.argmin(valid_tot_error)]\n",
    "rmse_star = np.min(valid_tot_error)\n",
    "print(\"Gamma_d value: \",gamma_d,\"\\n\")\n",
    "print('Gamma optimal Value:', gamma_star,\"\\n\")\n",
    "print('RMSE optimal Value:', rmse_star,\"\\n\")\n",
    "\n",
    "print(\"-------------------PLOT-------------------\")\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(gammas, tot_errors, marker = 'x', label = 'TrainRMSE')\n",
    "plt.plot(gammas, valid_tot_error, marker = 'o', color = 'red', label = 'ValidRMSE')\n",
    "# implement a log scale for gammas as mentioned in the question:\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Gammas')\n",
    "plt.ylabel('Average Root Mean Square Error(RMSE) over 5 folds')\n",
    "plt.title('Average Training and Validation RMSE vs. Gamma over 5 folds')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(gammas, tot_errors, marker = 'x', label = 'TrainRMSE')\n",
    "plt.plot(gammas, valid_tot_error, marker = 'o', color = 'red', label = 'ValidRMSE')\n",
    "print(\"-------------- Without Log Scale------------------\")\n",
    "plt.xlabel('Gammas without log scale')\n",
    "plt.ylabel('Average Root Mean Square Error(RMSE) over 5 folds')\n",
    "plt.title('Average Training and Validation RMSE vs. Gamma over 5 folds')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scale of Training errors are in lower end, hence i have also plotted them seperately for reference....\n",
    "plt.plot(gammas, tot_errors, marker = 'x', label = 'TrainRMSE')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = PrettyTable()\n",
    "fields = ['Gammas', 'Validation_Avg_RMSE', 'Std_of_RMSE']\n",
    "table.field_names = fields\n",
    "\n",
    "for iter in range(len(valid_tot_error)):\n",
    "    row = [gamma_[iter], valid_tot_error[iter], std_val[iter]]\n",
    "    table.add_row(row)\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K= range(10,101,10)\n",
    "2. Kfold\n",
    "3. K loop, gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(features, labels):\n",
    "    model = LinearRegression()\n",
    "    model.fit(features, labels)\n",
    "    return model\n",
    "\n",
    "# Creating model for KMeans this function has a few things which I discussed with my peers and implemented...\n",
    " \n",
    "def model_select_two(features, labels, folds = 5):\n",
    "    \n",
    "    K_errors = []\n",
    "    K_valid_errors = []\n",
    "    K_std_errors = []\n",
    "    K_std_val_errors = []\n",
    "    kfolds = KFold(n_splits=folds)\n",
    "    k_range = range(10, 101, 10)\n",
    "    optimal_rmse = float('inf')\n",
    "    optimal_k = None\n",
    "    optimal_gamma = None\n",
    "    optimal_centers = None\n",
    "    # setting K for range in 10, 100 with steps of 10\n",
    "    for iter in k_range:\n",
    "        # M / 32:\n",
    "        gamma_d = iter/32 \n",
    "        gammas = [gamma_d * 0.01, gamma_d * 0.1, gamma_d * 1, gamma_d * 10, gamma_d * 100]\n",
    "        gamma_train, gamma_val = [],[]\n",
    "        gamma_std_train, gamma_std_val = [],[]\n",
    "        # the beginning....\n",
    "        \n",
    "        for g in gammas:\n",
    "            train_errors = []\n",
    "            val_errors = []\n",
    "            for x, y in kfolds.split(features):\n",
    "                y_train, y_val = labels[x], labels[y]\n",
    "                train_X, val_X = features[x], features[y]\n",
    "                \n",
    "                # running KMeans multiple times as mentioned in question:\n",
    "                # The solution varies everytime I run it for 4,5 times\n",
    "                # So I am keeping 5 as constant now:\n",
    "                for i in range(5):\n",
    "                    kmeans = KMeans(n_clusters=iter, init='random').fit(train_X)\n",
    "                    centers = kmeans.cluster_centers_\n",
    "                    \n",
    "                m_tr = rbf_kernel(train_X, Y= centers, gamma=g)\n",
    "                model = linear_model(m_tr, y_train)\n",
    "                train_preds = model.predict(m_tr)\n",
    "                rmse_tr = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "                \n",
    "                # um's are the centers for training in KMeans\n",
    "                m_val = rbf_kernel(val_X, Y=centers, gamma=g)\n",
    "                val_preds = model.predict(m_val)\n",
    "                # according to the formula\n",
    "                rmse_val = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "                train_errors.append(rmse_tr)\n",
    "                val_errors.append(rmse_val)\n",
    "            \n",
    "            # The part to store centers reference was taken by discussing with peers and TA:\n",
    "            mean_val_error = np.mean(val_errors)\n",
    "            if mean_val_error < optimal_rmse:\n",
    "                optimal_rmse = mean_val_error\n",
    "                optimal_k = iter\n",
    "                optimal_gamma = g\n",
    "                optimal_centers = centers\n",
    "            \n",
    "            \"\"\"gamma_star = gammas[np.argmin(valid_tot_error)]\n",
    "            rmse_star = np.min(valid_tot_error)\"\"\"\n",
    "              \n",
    "            gamma_train.append(np.mean(train_errors))\n",
    "            gamma_val.append(np.mean(val_errors))\n",
    "            gamma_std_train.append(np.std(train_errors))\n",
    "            gamma_std_val.append(np.std(val_errors))\n",
    "              \n",
    "        K_errors.append(gamma_train) \n",
    "        K_valid_errors.append(gamma_val)\n",
    "        K_std_errors.append(gamma_std_train)\n",
    "        K_std_val_errors.append(gamma_std_val)\n",
    "    \n",
    "    print(f\"K Star: {optimal_k}, Gamma Star: {optimal_gamma}, RMSE star: {optimal_rmse}\")\n",
    "    return K_errors, K_valid_errors, K_std_errors, K_std_val_errors, optimal_centers, optimal_k, optimal_gamma, optimal_rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "K_tot_errors, K_valid_tot_error, K_std_errors, K_std_val_errors, k_centers, k_star, k_gamma_star, rmse_star = model_select_two(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_d = k_star/32\n",
    "gamma = [0.01 * gamma_d, 0.1 * gamma_d, gamma_d, 10 * gamma_d, 100 * gamma_d]\n",
    "\n",
    "plt.plot(gamma, K_tot_errors[-1], label = 'Training RMSE')\n",
    "plt.plot(gamma, K_valid_tot_error[-1], label = 'Validation RMSE')\n",
    "# Plotting over a log scale...\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Gammas')\n",
    "plt.ylabel('Average Root Mean Square Error(RMSE) over 5 folds ')\n",
    "plt.title('Average Training and Validation RMSE vs. Gamma over 5 folds over KMeans')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gamma, K_tot_errors[-1], label = 'Training RMSE')\n",
    "plt.plot(gamma, K_valid_tot_error[-1], label = 'Validation RMSE')\n",
    "# Plotting over a log scale...\n",
    "print(\"---------------Without Log Scale--------------------\")\n",
    "plt.xlabel('Gammas without log scale')\n",
    "plt.ylabel('Average Root Mean Square Error(RMSE) over 5 folds ')\n",
    "plt.title('Average Training and Validation RMSE vs. Gamma over 5 folds over KMeans')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Individual plots in LOG Scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gamma, K_tot_errors[-1], label = 'Training RMSE')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Gammas')\n",
    "plt.ylabel('Average Root Mean Square Error(RMSE) over 5 folds ')\n",
    "plt.title('Average Training RMSE vs. Gamma over 5 folds over KMeans')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gamma, K_valid_tot_error[-1], label = 'Validation RMSE', color = 'red')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Gammas')\n",
    "plt.ylabel('Average Root Mean Square Error(RMSE) over 5 folds ')\n",
    "plt.title('Average Validation RMSE vs. Gamma over 5 folds over KMeans')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot with Optimal centers and data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(features[:, 0], features[:, 1], s=10, color='blue', label='Features')\n",
    "plt.scatter(k_centers[:, 0], k_centers[:, 1], s=50, color='red', marker='x', label='Best Cluster Centers')\n",
    "plt.title('Training Data Points and Best Cluster Centers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot with Validation RMSE and it's standard deviation against all K's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since my gamma_ came to be 1 being multiplied by best K value of 90 and if I plot it\n",
    "# It will be the third column i.e for gamma_ = 1\n",
    "k_range = range(10, 101, 10)  \n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(list(k_range), [x[2] for x in K_valid_tot_error], label = \"Validation RMSE\")\n",
    "plt.plot(list(k_range), [x[2] for x in K_std_val_errors], label = \"STD of Validation RMSE\")\n",
    "#plt.errorbar(list(k_range), [x[2] for x in K_valid_tot_error], yerr=[x[2] for x in K_std_val_errors], fmt='-o', label='Validation RMSE')\n",
    "plt.title(\"Validation RMSE and it's Standard Deviation vs. K for best gamma\")\n",
    "plt.xlabel('K = Number of Clusters')\n",
    "plt.ylabel('Validation RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Or if you want it in a single line with strokes for marking it it can also be done\n",
    "with the help of errorbar this part was taken by referencing to errorbars \n",
    "in STACK-overflow\n",
    "\"\"\"\n",
    "plt.errorbar(list(k_range), [x[2] for x in K_valid_tot_error], yerr=[x[2] for x in K_std_val_errors], fmt='-o', label='Validation RMSE')\n",
    "plt.title(\"Validation RMSE and it's Standard Deviation vs. K for best gamma\")\n",
    "plt.xlabel('K = Number of Clusters')\n",
    "plt.ylabel('Validation RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plotting Both seperately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(k_range), [x[2] for x in K_valid_tot_error], label='Validation RMSE')\n",
    "plt.title(\"Validation RMSE vs. K for best Gamma\")\n",
    "plt.xlabel('K = Number of Clusters')\n",
    "plt.ylabel('Validation RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(k_range), [x[2] for x in K_std_val_errors], label='Standard Deviation of RMSE', color = 'orange')\n",
    "plt.title(\"Standard Deviation of  RMSE vs. K for best Gamma\")\n",
    "plt.xlabel('K = Number of Clusters')\n",
    "plt.ylabel('Validation RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = PrettyTable()\n",
    "fields = ['KMeans Validation_Avg_RMSE', 'KMeans Std_of_RMSE']\n",
    "table.field_names = fields\n",
    "\n",
    "for iter in range(len(K_valid_tot_error[-1])):\n",
    "    row = [K_valid_tot_error[-1][iter], K_std_val_errors[-1][iter]]\n",
    "    table.add_row(row)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f)\n",
    "* Testing on Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_t, labels_t = data(df_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Testing Model part B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we already train it using cross validation we just need to train it on \n",
    "# Linear Regression model and obtain TEST RMSE as directed in the question\n",
    "model = LinearRegression().fit(features, labels)\n",
    "\n",
    "test_preds = model.predict(features_t)\n",
    "rmse_test = np.sqrt(mean_squared_error(labels_t, test_preds))\n",
    "print(f\"RMSE while Testing Model B: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Testing for Model part C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we have Optimal Gamma as 0.25 obtained from the C part\n",
    "training = rbf_kernel(features, gamma=0.25)\n",
    "model = LinearRegression()\n",
    "model.fit(training, labels)\n",
    "\n",
    "# Testing:\n",
    "testing = rbf_kernel(features_t, features, 0.25)\n",
    "test_c_preds = model.predict(testing)\n",
    "rmse_test_c = np.sqrt(mean_squared_error(labels_t, test_c_preds))\n",
    "print(f\"RMSE while Testing Model C: {rmse_test_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Testing for Model part D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will run KMeans again for 5 times as i did in my training as mentioned in the question:\n",
    "# As we get in the D part that K star is 100 and Gamma star is 3.125 I will use that...\n",
    "for i in range(5):\n",
    "    kmeans = KMeans(n_clusters=100, init='random').fit(features)\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "# Training with K star and Gamma Star\n",
    "training_d = rbf_kernel(features, Y=centers, gamma=3.125)\n",
    "testing_d = rbf_kernel(features_t, Y=centers, gamma=3.125)\n",
    "model = LinearRegression()\n",
    "model.fit(training_d, labels)\n",
    "\n",
    "# Testing\n",
    "predictions_test = model.predict(testing_d)\n",
    "rmse_test_d = np.sqrt(mean_squared_error(labels_t, predictions_test))\n",
    "print(f\"RMSE while Testing Model D: {rmse_test_d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
